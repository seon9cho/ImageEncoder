{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import copy, math\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.autograd import functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10, 10),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(10, 10),\n",
    "                      nn.LogSoftmax(dim = 1)\n",
    "                     )\n",
    "\n",
    "# Define the loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 10)\n",
    "y = torch.randint(10, (5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)\n",
    "loss = criterion(out, y)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0243,  0.0232,  0.0168, -0.0002,  0.0342,  0.0296, -0.0038,  0.0020,\n",
       "          0.0382,  0.0123],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [-0.0283,  0.0104,  0.0184, -0.0161,  0.0157, -0.0017, -0.0410, -0.0057,\n",
       "         -0.0103, -0.0236],\n",
       "        [-0.0464, -0.0092, -0.0254, -0.0331, -0.0147, -0.0204, -0.0192, -0.0252,\n",
       "         -0.0519, -0.0182],\n",
       "        [ 0.0060, -0.0003,  0.0081, -0.0196, -0.0027, -0.0197, -0.0278, -0.0110,\n",
       "          0.0144, -0.0157],\n",
       "        [-0.0546, -0.0246, -0.0418, -0.0431, -0.0553, -0.0701, -0.0252, -0.0353,\n",
       "         -0.0552, -0.0324],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000,  0.0000],\n",
       "        [ 0.0089,  0.0050,  0.0105,  0.0283,  0.0152,  0.0299,  0.0226,  0.0204,\n",
       "          0.0038,  0.0157],\n",
       "        [ 0.0185,  0.0078,  0.0214,  0.0152,  0.0187,  0.0199,  0.0006,  0.0140,\n",
       "          0.0216,  0.0052]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PowBackward0 at 0x1a5ed0b4848>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5, requires_grad=True)\n",
    "y = x.pow(2)\n",
    "y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([2., 3.], requires_grad=True)\n",
    "b = torch.tensor([6., 4.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = 3*a**3 - b**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_grad = torch.tensor([1., 1.])\n",
    "Q.backward(gradient=external_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([36., 81.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.7994, 0.0000],\n",
       "          [0.9090, 0.0000]],\n",
       "\n",
       "         [[0.2644, 0.8997],\n",
       "          [0.6977, 0.4545]]],\n",
       "\n",
       "\n",
       "        [[[0.2644, 0.8997],\n",
       "          [0.6977, 0.4545]],\n",
       "\n",
       "         [[0.0000, 0.5288],\n",
       "          [0.0000, 1.3953]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def XTX(X):\n",
    "    return X.T @ X\n",
    "inp = torch.rand(2, 2)\n",
    "A = torch.rand(2, 2)\n",
    "J = F.jacobian(XTX, inp)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1.0160, 0.5550],\n",
       "         [0.5550, 0.5567]]),\n",
       " tensor([[0.8123, 0.7985],\n",
       "         [0.8075, 0.7556]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.vjp(XTX, inp, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3480, 0.5575],\n",
       "        [0.1465, 0.3122]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8123, 0.8075],\n",
       "        [0.7985, 0.7556]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(A.T + A) @ inp.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8123, 0.7985],\n",
       "        [0.8075, 0.7556]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp @ (A.T + A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.6954, 0.0000],\n",
       "          [0.9645, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.6954],\n",
       "          [0.0000, 0.9645]]],\n",
       "\n",
       "\n",
       "        [[[0.8849, 0.0000],\n",
       "          [0.8585, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.8849],\n",
       "          [0.0000, 0.8585]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M = torch.rand(2,2)\n",
    "def MX(X):\n",
    "    return M @ X\n",
    "inp = torch.rand(2, 2)\n",
    "A = torch.rand(2, 2)\n",
    "J = F.jacobian(MX, inp)\n",
    "J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec = nn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
