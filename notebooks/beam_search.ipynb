{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path\n",
    "sys.path.insert(1, 'C:\\\\Users\\\\scj14\\\\BYU\\\\research\\\\image_encoder\\\\github\\\\experiment1')\n",
    "\n",
    "from process_data import save_maps, load_maps, index2sentence, subsequent_mask\n",
    "from encoderdecoder import EncoderDecoder, save_model, load_model\n",
    "from dataset import TranslationDataset, AutoencoderDataset, padding_collate_fn, Batch\n",
    "from image import tensor2image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "PAD = 0\n",
    "SOS = 1\n",
    "EOS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"../text_corpora/prepared/\"\n",
    "data_dir = \"eng/\"\n",
    "filename = \"toy_data.txt\"\n",
    "map_dir = '../outputs/maps/'\n",
    "model_dir = '../outputs/models/'\n",
    "train_name = 'toy_data_txt-2023-02-13-11-11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting lines to indices...\n"
     ]
    }
   ],
   "source": [
    "file_path = base_dir + data_dir + filename\n",
    "dataset = AutoencoderDataset(file_path, min_freq_vocab=5)\n",
    "word2index, index2word = load_maps(train_name, map_dir=map_dir)\n",
    "dataset.init_using_existing_maps(None, word2index, index2word)\n",
    "vocab_size = len(dataset.word2index)\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=32, \n",
    "    pin_memory=True, \n",
    "    collate_fn=padding_collate_fn, \n",
    "    shuffle=False\n",
    ")\n",
    "model = load_model(train_name, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len=50):\n",
    "    src = src.unsqueeze(0)\n",
    "    src_mask = src_mask.unsqueeze(0)\n",
    "    x = model.encode(src, src_mask)\n",
    "    memory, image = model.extract_features(x)\n",
    "    ys = torch.ones(1, 1).fill_(SOS).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        ys = Variable(ys)\n",
    "        ys_mask = Variable(subsequent_mask(ys.size(1)).type_as(src.data))\n",
    "        out = model.decode(ys, memory, ys_mask)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "        if next_word.item() == EOS:\n",
    "            break\n",
    "    return ys[0], image\n",
    "\n",
    "def beam_search(model, src, src_mask, k=5, max_len=50):\n",
    "    src = src.unsqueeze(0)\n",
    "    src_mask = src_mask.unsqueeze(0)\n",
    "    x = model.encode(src, src_mask)\n",
    "    memory, image = model.extract_features(x)\n",
    "    ys = torch.ones(1, 1).fill_(SOS).type_as(src.data)\n",
    "    top_sequences = [(ys, 0, False)]\n",
    "    for i in range(50-1):\n",
    "        new_sequences = []\n",
    "        for seq, score, eos_bool in top_sequences:\n",
    "            if eos_bool:\n",
    "                new_sequences.append((seq, score, eos_bool))\n",
    "                continue\n",
    "            seq = Variable(seq)\n",
    "            mask = Variable(subsequent_mask(seq.size(1)).type_as(src.data))\n",
    "            out = model.decode(seq, memory, mask)\n",
    "            dist = model.generator(out[:, -1])\n",
    "            probs, words = torch.topk(dist, k)\n",
    "            for prob, word in zip(probs[0], words[0]):\n",
    "                new_seq = torch.cat([seq, torch.ones(1, 1).type_as(src.data).fill_(word)], dim=1)\n",
    "                new_score = score + prob\n",
    "                new_eos_bool = True if word.item() == EOS else False\n",
    "                new_sequences.append((new_seq, new_score, new_eos_bool))\n",
    "        top_sequences = sorted(new_sequences, key=lambda val: val[1], reverse=True)\n",
    "        top_sequences = top_sequences[:k]\n",
    "        if sum(b for _, _, b in top_sequences) == k:\n",
    "            break\n",
    "    return top_sequences, image\n",
    "\n",
    "def calc_src_prob(model, src, src_mask):\n",
    "    src = src.unsqueeze(0)\n",
    "    src_mask = src_mask.unsqueeze(0)\n",
    "    x = model.encode(src, src_mask)\n",
    "    memory, image = model.extract_features(x)\n",
    "    prob = 0\n",
    "    print(src)\n",
    "    for i in range(len(src[0])-1):\n",
    "        ys = src[0, :i+1].unsqueeze(0)\n",
    "        ys_mask = Variable(subsequent_mask(ys.size(1)).type_as(src.data))\n",
    "        out = model.decode(ys, memory, ys_mask)\n",
    "        dist = model.generator(out[:, -1])\n",
    "        prob += dist[0, src[0,i+1]].item()\n",
    "        print(prob)\n",
    "    out = model.decode(src, memory, src_mask)\n",
    "    dist = model.generator(out[:,-1])\n",
    "    prob += dist[0, EOS].item()\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = Batch(dataset[4:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1, 15, 28, 17, 29, 30, 31, 32, 19, 33, 34, 26, 19, 35,  8]],\n",
      "       device='cuda:0')\n",
      "-0.09190216660499573\n",
      "-0.766737312078476\n",
      "-0.878957487642765\n",
      "-2.959669329226017\n",
      "-3.71846554428339\n",
      "-9.085223890841007\n",
      "-11.248544670641422\n",
      "-11.287339769303799\n",
      "-18.501816354691982\n",
      "-20.546979032456875\n",
      "-20.869659088551998\n",
      "-21.58021166175604\n",
      "-21.765391387045383\n",
      "-21.848864771425724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-21.926146119832993"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_src_prob(model, batch.src[0], batch.src_pad_mask[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "greedy, image = greedy_decode(model, batch.src[0], batch.src_pad_mask[0])\n",
    "beam, _ = beam_search(model, batch.src[0], batch.src_pad_mask[0], k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = batch.src[0]\n",
    "src_len = (src != 0).sum().item()\n",
    "inp = index2sentence(src[1:src_len].tolist(), index2word)\n",
    "greedy_out = index2sentence(greedy[1:-1].tolist(), index2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tom could not help but notice all the beautiful women on the beach .'"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tom could not help but cry on the other side .'"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "greedy_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tom could not eat the food he was in .\n",
      "tom could not eat the food he was in my eyes .\n",
      "tom could not eat the food in the sky .\n",
      "tom and mary could not feel at the back of the world .\n",
      "tom could not help but cry on the way all .\n",
      "tom could not eat the food he was in the bathroom .\n",
      "tom and mary could not feel at the back of the town .\n",
      "tom could not eat the food he was in their .\n",
      "tom could not eat the food he was in the woods .\n",
      "tom and mary were not even in the back of the food .\n",
      "tom could not eat the food he was in the .\n",
      "tom and mary could not find the same food in town .\n",
      "tom and mary were not even in the back of the meeting .\n",
      "tom and mary could not feel at the back of the city .\n",
      "tom and mary were not even in the back of the election .\n",
      "tom and mary could not find all the same food in her .\n",
      "tom and mary were not even in the back of the speech .\n",
      "tom could not help but cry on the way all the other .\n",
      "tom and mary could not find all the same food in his bedroom .\n",
      "tom and mary could not find all the same food in his .\n"
     ]
    }
   ],
   "source": [
    "for seq, _, _ in beam:\n",
    "    print(index2sentence(seq[0][1:-1].tolist(), index2word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-8.869412422180176\n",
      "-9.547994613647461\n",
      "-9.809532165527344\n",
      "-9.952197074890137\n",
      "-11.857104301452637\n"
     ]
    }
   ],
   "source": [
    "for _, p, _ in beam:\n",
    "    print(p.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
